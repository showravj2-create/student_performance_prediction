# ===================================================
# ðŸŽ“ Student Performance Prediction
# Full Workflow: EDA, Modeling, Evaluation
# ===================================================

# ðŸ“Œ Step 1: Import libraries
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score

# ===================================================
# ðŸ“Œ Step 2: Setup paths
# ===================================================
# Base directory (repo root)
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath("__file__")))

# Paths to dataset and results
DATA_PATH = os.path.join(BASE_DIR, "data", "student-mat.csv")
RESULTS_DIR = os.path.join(BASE_DIR, "results", "figures")

# Create results directory if it doesn't exist
os.makedirs(RESULTS_DIR, exist_ok=True)

# ===================================================
# ðŸ“Œ Step 3: Load dataset
# ===================================================
df = pd.read_csv(DATA_PATH, sep=';')
print("Dataset loaded successfully. Shape:", df.shape)
df.head()

# ===================================================
# ðŸ“Œ Step 4: Basic Exploration
# ===================================================
print("\nColumns:", df.columns.tolist())
print("\nMissing values:\n", df.isnull().sum())
print("\nSummary statistics:\n", df.describe())

# ===================================================
# ðŸ“Œ Step 5: Exploratory Data Analysis (EDA)
# ===================================================

# Distribution of final grade
plt.figure(figsize=(6,4))
sns.histplot(df["G3"], bins=15, kde=True, color="blue")
plt.title("Distribution of Final Grade (G3)")
plt.xlabel("Final Grade")
plt.ylabel("Count")
plt.savefig(os.path.join(RESULTS_DIR, "grade_distribution.png"))
plt.show()

# Correlation heatmap
plt.figure(figsize=(12,8))
sns.heatmap(df.corr(), cmap="coolwarm", annot=False)
plt.title("Correlation Heatmap")
plt.savefig(os.path.join(RESULTS_DIR, "correlation_heatmap.png"))
plt.show()

# Study time vs Final grade
plt.figure(figsize=(6,4))
sns.boxplot(x="studytime", y="G3", data=df)
plt.title("Study Time vs Final Grade")
plt.savefig(os.path.join(RESULTS_DIR, "studytime_vs_grade.png"))
plt.show()

# ===================================================
# ðŸ“Œ Step 6: Data Preprocessing
# ===================================================
# Encode categorical variables
df_encoded = pd.get_dummies(df, drop_first=True)

# Features and target
X = df_encoded.drop("G3", axis=1)
y = df_encoded["G3"]

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Feature scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print("Data preprocessing completed.")

# ===================================================
# ðŸ“Œ Step 7: Train Models
# ===================================================
models = {
    "Linear Regression": LinearRegression(),
    "Random Forest": RandomForestRegressor(random_state=42),
    "Support Vector Regressor": SVR()
}

results = {}

for name, model in models.items():
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    
    rmse = np.sqrt(mean_squared_error(y_test, preds))
    r2 = r2_score(y_test, preds)
    
    results[name] = {"RMSE": rmse, "R2": r2}
    print(f"{name}: RMSE={rmse:.2f}, RÂ²={r2:.2f}")

# ===================================================
# ðŸ“Œ Step 8: Compare Models
# ===================================================
results_df = pd.DataFrame(results).T
results_df

# ===================================================
# ðŸ“Œ Step 9: Visualization of Model Performance
# ===================================================
plt.figure(figsize=(8,5))
sns.barplot(x=results_df.index, y="R2", data=results_df.reset_index())
plt.title("Model Comparison (RÂ² Score)")
plt.ylabel("RÂ² Score")
plt.xlabel("Model")
plt.ylim(0,1)
plt.savefig(os.path.join(RESULTS_DIR, "model_comparison_r2.png"))
plt.show()

# ===================================================
# ðŸ“Œ Step 10: Prediction vs Actual (Best Model)
# ===================================================
best_model = RandomForestRegressor(random_state=42)
best_model.fit(X_train, y_train)
preds = best_model.predict(X_test)

plt.figure(figsize=(6,6))
plt.scatter(y_test, preds, alpha=0.6, color="blue")
plt.plot([0,20],[0,20], color="red", linestyle="--")
plt.xlabel("Actual Grades")
plt.ylabel("Predicted Grades")
plt.title("Random Forest: Predicted vs Actual Grades")
plt.savefig(os.path.join(RESULTS_DIR, "rf_pred_vs_actual.png"))
plt.show()# =============================
# ðŸ“Œ Step 4: Exploratory Data Analysis (EDA)
# =============================

# Distribution of final grade
plt.figure(figsize=(6,4))
sns.histplot(df["G3"], bins=15, kde=True, color="blue")
plt.title("Distribution of Final Grade (G3)")
plt.show()

# Correlation heatmap
plt.figure(figsize=(12,8))
sns.heatmap(df.corr(), cmap="coolwarm", annot=False)
plt.title("Correlation Heatmap")
plt.show()

# Study time vs Final grade
plt.figure(figsize=(6,4))
sns.boxplot(x="studytime", y="G3", data=df)
plt.title("Study Time vs Final Grade")
plt.show()

# =============================
# ðŸ“Œ Step 5: Data Preprocessing
# =============================
# Convert categorical to numeric
df_encoded = pd.get_dummies(df, drop_first=True)

X = df_encoded.drop("G3", axis=1)
y = df_encoded["G3"]

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Scale features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# =============================
# ðŸ“Œ Step 6: Train Models
# =============================

models = {
    "Linear Regression": LinearRegression(),
    "Random Forest": RandomForestRegressor(random_state=42),
    "Support Vector Regressor": SVR()
}

results = {}

for name, model in models.items():
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    
    rmse = np.sqrt(mean_squared_error(y_test, preds))
    r2 = r2_score(y_test, preds)
    
    results[name] = {"RMSE": rmse, "R2": r2}
    
    print(f"{name}: RMSE={rmse:.2f}, RÂ²={r2:.2f}")

# =============================
# ðŸ“Œ Step 7: Compare Models
# =============================
results_df = pd.DataFrame(results).T
results_df

# =============================
# ðŸ“Œ Step 8: Visualization of Model Performance
# =============================
plt.figure(figsize=(8,5))
sns.barplot(x=results_df.index, y="R2", data=results_df.reset_index())
plt.title("Model Comparison (RÂ² Score)")
plt.ylabel("RÂ² Score")
plt.xlabel("Model")
plt.ylim(0,1)
plt.show()

# =============================
# ðŸ“Œ Step 9: Prediction vs Actual (Best Model)
# =============================
best_model = RandomForestRegressor(random_state=42)
best_model.fit(X_train, y_train)
preds = best_model.predict(X_test)

plt.figure(figsize=(6,6))
plt.scatter(y_test, preds, alpha=0.6, color="blue")
plt.plot([0,20],[0,20], color="red", linestyle="--")
plt.xlabel("Actual Grades")
plt.ylabel("Predicted Grades")
plt.title("Random Forest: Predicted vs Actual Grades")
plt.show()
