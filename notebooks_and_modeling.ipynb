# =============================
# ðŸŽ“ Student Performance Prediction
# Exploratory Data Analysis & Modeling
# =============================

# ðŸ“Œ Step 1: Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score

# =============================
# ðŸ“Œ Step 2: Load dataset
# =============================
df = pd.read_csv("../data/student-mat.csv", sep=';')

# Show first rows
df.head()

# =============================
# ðŸ“Œ Step 3: Basic Exploration
# =============================
print("Dataset shape:", df.shape)
print("\nColumns:", df.columns.tolist())
print("\nMissing values:\n", df.isnull().sum())

# Summary stats
df.describe()

# =============================
# ðŸ“Œ Step 4: Exploratory Data Analysis (EDA)
# =============================

# Distribution of final grade
plt.figure(figsize=(6,4))
sns.histplot(df["G3"], bins=15, kde=True, color="blue")
plt.title("Distribution of Final Grade (G3)")
plt.show()

# Correlation heatmap
plt.figure(figsize=(12,8))
sns.heatmap(df.corr(), cmap="coolwarm", annot=False)
plt.title("Correlation Heatmap")
plt.show()

# Study time vs Final grade
plt.figure(figsize=(6,4))
sns.boxplot(x="studytime", y="G3", data=df)
plt.title("Study Time vs Final Grade")
plt.show()

# =============================
# ðŸ“Œ Step 5: Data Preprocessing
# =============================
# Convert categorical to numeric
df_encoded = pd.get_dummies(df, drop_first=True)

X = df_encoded.drop("G3", axis=1)
y = df_encoded["G3"]

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Scale features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# =============================
# ðŸ“Œ Step 6: Train Models
# =============================

models = {
    "Linear Regression": LinearRegression(),
    "Random Forest": RandomForestRegressor(random_state=42),
    "Support Vector Regressor": SVR()
}

results = {}

for name, model in models.items():
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    
    rmse = np.sqrt(mean_squared_error(y_test, preds))
    r2 = r2_score(y_test, preds)
    
    results[name] = {"RMSE": rmse, "R2": r2}
    
    print(f"{name}: RMSE={rmse:.2f}, RÂ²={r2:.2f}")

# =============================
# ðŸ“Œ Step 7: Compare Models
# =============================
results_df = pd.DataFrame(results).T
results_df

# =============================
# ðŸ“Œ Step 8: Visualization of Model Performance
# =============================
plt.figure(figsize=(8,5))
sns.barplot(x=results_df.index, y="R2", data=results_df.reset_index())
plt.title("Model Comparison (RÂ² Score)")
plt.ylabel("RÂ² Score")
plt.xlabel("Model")
plt.ylim(0,1)
plt.show()

# =============================
# ðŸ“Œ Step 9: Prediction vs Actual (Best Model)
# =============================
best_model = RandomForestRegressor(random_state=42)
best_model.fit(X_train, y_train)
preds = best_model.predict(X_test)

plt.figure(figsize=(6,6))
plt.scatter(y_test, preds, alpha=0.6, color="blue")
plt.plot([0,20],[0,20], color="red", linestyle="--")
plt.xlabel("Actual Grades")
plt.ylabel("Predicted Grades")
plt.title("Random Forest: Predicted vs Actual Grades")
plt.show()
