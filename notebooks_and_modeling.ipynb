# ===================================================
# ðŸŽ“ Student Performance Prediction
# Full Workflow: Merge Datasets, EDA, Modeling
# ===================================================

# ðŸ“Œ Step 1: Import libraries
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score

# ===================================================
# ðŸ“Œ Step 2: Setup paths
# ===================================================
DATA_DIR = "data"  # data folder is at the same level as notebook
RESULTS_DIR = os.path.join("results", "figures")

# Create results folder if it doesn't exist
os.makedirs(RESULTS_DIR, exist_ok=True)

# ===================================================
# ðŸ“Œ Step 3: Load datasets
# ===================================================
df_math = pd.read_csv(os.path.join(DATA_DIR, "student-mat.csv"), sep=';')
df_por = pd.read_csv(os.path.join(DATA_DIR, "student-por.csv"), sep=';')

print("Math dataset shape:", df_math.shape)
print("Portuguese dataset shape:", df_por.shape)

# ===================================================
# ðŸ“Œ Step 4: Merge datasets
# ===================================================
common_cols = [
    'school','sex','age','address','famsize','Pstatus','Medu','Fedu','Mjob','Fjob',
    'reason','guardian','traveltime','studytime','failures','schoolsup','famsup','paid',
    'activities','nursery','higher','internet','romantic','famrel','freetime','goout',
    'Dalc','Walc','health','absences'
]

df_combined = pd.merge(df_math, df_por, on=common_cols, how='outer', suffixes=('_math', '_por'))
print("Combined dataset shape:", df_combined.shape)
df_combined.head()

# ===================================================
# ðŸ“Œ Step 5: Basic Exploration
# ===================================================
print("\nColumns:", df_combined.columns.tolist())
print("\nMissing values:\n", df_combined.isnull().sum())
print("\nSummary statistics:\n", df_combined.describe())

# ===================================================
# ðŸ“Œ Step 6: Exploratory Data Analysis (EDA)
# ===================================================
plt.figure(figsize=(6,4))
sns.histplot(df_combined["G3_math"].fillna(df_combined["G3_por"]), bins=15, kde=True, color="blue")
plt.title("Distribution of Final Grade (G3)")
plt.xlabel("Final Grade")
plt.ylabel("Count")
plt.savefig(os.path.join(RESULTS_DIR, "grade_distribution.png"))
plt.show()

plt.figure(figsize=(12,8))
sns.heatmap(df_combined.corr(), cmap="coolwarm", annot=False)
plt.title("Correlation Heatmap")
plt.savefig(os.path.join(RESULTS_DIR, "correlation_heatmap.png"))
plt.show()

plt.figure(figsize=(6,4))
sns.boxplot(x="studytime", y=df_combined["G3_math"].fillna(df_combined["G3_por"]), data=df_combined)
plt.title("Study Time vs Final Grade")
plt.savefig(os.path.join(RESULTS_DIR, "studytime_vs_grade.png"))
plt.show()

# ===================================================
# ðŸ“Œ Step 7: Data Preprocessing
# ===================================================
# Use G3_math if available, else G3_por
df_combined['G3'] = df_combined['G3_math'].fillna(df_combined['G3_por'])
df_combined = df_combined.drop(['G3_math','G3_por'], axis=1)

# One-hot encode categorical variables
df_encoded = pd.get_dummies(df_combined, drop_first=True)

X = df_encoded.drop("G3", axis=1)
y = df_encoded["G3"]

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Feature scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print("Data preprocessing completed.")

# ===================================================
# ðŸ“Œ Step 8: Train Models
# ===================================================
models = {
    "Linear Regression": LinearRegression(),
    "Random Forest": RandomForestRegressor(random_state=42),
    "Support Vector Regressor": SVR()
}

results = {}

for name, model in models.items():
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    
    rmse = np.sqrt(mean_squared_error(y_test, preds))
    r2 = r2_score(y_test, preds)
    
    results[name] = {"RMSE": rmse, "R2": r2}
    print(f"{name}: RMSE={rmse:.2f}, RÂ²={r2:.2f}")

# ===================================================
# ðŸ“Œ Step 9: Compare Models
# ===================================================
results_df = pd.DataFrame(results).T
results_df

plt.figure(figsize=(8,5))
sns.barplot(x=results_df.index, y="R2", data=results_df.reset_index())
plt.title("Model Comparison (RÂ² Score)")
plt.ylabel("RÂ² Score")
plt.xlabel("Model")
plt.ylim(0,1)
plt.savefig(os.path.join(RESULTS_DIR, "model_comparison_r2.png"))
plt.show()

# ===================================================
# ðŸ“Œ Step 10: Prediction vs Actual (Best Model)
# ===================================================
best_model = RandomForestRegressor(random_state=42)
best_model.fit(X_train, y_train)
preds = best_model.predict(X_test)

plt.figure(figsize=(6,6))
plt.scatter(y_test, preds, alpha=0.6, color="blue")
plt.plot([0,20],[0,20], color="red", linestyle="--")
plt.xlabel("Actual Grades")
plt.ylabel("Predicted Grades")
plt.title("Random Forest: Predicted vs Actual Grades")
plt.savefig(os.path.join(RESULTS_DIR, "rf_pred_vs_actual.png"))
plt.show()
